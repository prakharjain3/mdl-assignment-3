{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World\n",
    "\n",
    "|       | reward + 1 | Penalty -1 |\n",
    "|-------|------------|------------|\n",
    "|       |  &nbsp;    |  &nbsp;    |\n",
    "|       | wall       |            |\n",
    "| start |            |            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1. Write a code in Python implementing Value iteration for a grid world given in the\n",
    "image above\n",
    "Values you will require:\n",
    "1. The reward for reaching the goal state = 1\n",
    "2. The penalty for reaching the red state = -1\n",
    "3. Step cost = -0.04\n",
    "4. Probability of going in the direction of the action = 0.7\n",
    "5. Probability of going in a direction perpendicular to the action = 0.15\n",
    "6. Discount Factor = 0.95\n",
    "Print the utility value of each cell in the grid after each iteration until the values\n",
    "converge. (Assume the values converge when the difference between the utilities\n",
    "for each cell is <= 0.0001)\n",
    "Note: The agent does not change its state if it hits a wall or the boundaries\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "GOAL_STATE = (0, 1)\n",
    "RED_STATE = (0, 2)\n",
    "STEP_COST = -0.04\n",
    "GAMMA = 0.95\n",
    "DELTA = 0.0001\n",
    "WALL_STATE = (2, 1)\n",
    "\n",
    "PROB_ACTION = 0.7\n",
    "PROB_OTHER_ACTION = 0.15\n",
    "\n",
    "U = [[0, 1, -1],\n",
    "     [0 for i in range(3)],\n",
    "     [0, None, 0],\n",
    "     [0 for i in range(3)]]\n",
    "\n",
    "NUM_ROWS = len(U)\n",
    "NUM_COLS = len(U[0])\n",
    "\n",
    "ACTIONS = [\"DOWN\", \"LEFT\", \"UP\", \"RIGHT\"] # Down, Left, Up, Right\n",
    "\n",
    "def get_valid_actions(r, c):\n",
    "    valid_actions = []\n",
    "    if r > 0:\n",
    "        valid_actions.append(\"UP\")\n",
    "    if r < len(U) - 1:\n",
    "        valid_actions.append(\"DOWN\")\n",
    "    if c > 0:\n",
    "        valid_actions.append(\"LEFT\")\n",
    "    if c < len(U[0]) - 1:\n",
    "        valid_actions.append(\"RIGHT\")\n",
    "    return valid_actions\n",
    "\n",
    "def get_state_corresponding_to_the_action(r, c, action):\n",
    "    if action == \"UP\":\n",
    "        if r == 0 or (r - 1, c) == WALL_STATE:\n",
    "            return [r, c]\n",
    "        return [r - 1, c]\n",
    "    elif action == \"DOWN\":\n",
    "        if r == len(U) - 1 or (r + 1, c) == WALL_STATE:\n",
    "            return [r, c]\n",
    "        return [r + 1, c]\n",
    "    elif action == \"LEFT\":\n",
    "        if c == 0 or (r, c - 1) == WALL_STATE:\n",
    "            return [r, c]\n",
    "        return [r, c - 1]\n",
    "    elif action == \"RIGHT\":\n",
    "        if c == len(U[0]) - 1 or (r, c + 1) == WALL_STATE:\n",
    "            return [r, c]\n",
    "        return [r, c + 1]\n",
    "    \n",
    "def get_perpendicular_actions(action):\n",
    "    if action == \"UP\" or action == \"DOWN\":\n",
    "        return [\"LEFT\", \"RIGHT\"]\n",
    "    elif action == \"LEFT\" or action == \"RIGHT\":\n",
    "        return [\"UP\", \"DOWN\"]\n",
    "    \n",
    "def get_possible_other_states(r, c, action):\n",
    "    possible_other_states = []\n",
    "    for action in get_perpendicular_actions(action):\n",
    "        possible_other_states.append(get_state_corresponding_to_the_action(r, c, action))\n",
    "    return possible_other_states\n",
    "\n",
    "def get_value_state(U, r, c, action):\n",
    "    value_state = 0\n",
    "\n",
    "    x, y = get_state_corresponding_to_the_action(r, c, action)\n",
    "    value_state += PROB_ACTION * (STEP_COST + GAMMA * U[x][y])\n",
    "\n",
    "    for other_state in get_possible_other_states(r, c, action):\n",
    "        value_state += PROB_OTHER_ACTION * (STEP_COST + GAMMA * U[other_state[0]][other_state[1]])\n",
    "    return value_state\n",
    "\n",
    "def value_iteration(U):\n",
    "    i = 0\n",
    "    while True:\n",
    "        nextU =[[0, 1, -1],\n",
    "                [0 for i in range(3)],\n",
    "                [0, None, 0],\n",
    "                [0 for i in range(3)]]\n",
    "        delta = 0\n",
    "        for r in range(NUM_ROWS):\n",
    "            for c in range(NUM_COLS):\n",
    "                if (r, c) == RED_STATE or (r, c) == WALL_STATE or (r, c) == GOAL_STATE:\n",
    "                    continue\n",
    "                utility = []\n",
    "                for action in get_valid_actions(r, c):\n",
    "                    utility.append(get_value_state(U, r, c, action))\n",
    "                nextU[r][c] = max(utility)\n",
    "                delta = max(delta, abs(U[r][c] - nextU[r][c]))\n",
    "        U = nextU\n",
    "        if delta < DELTA:\n",
    "            break\n",
    "        print(\"Iteration: \", i+1)\n",
    "        i += 1\n",
    "        for row in U:\n",
    "            print(row)\n",
    "    return U\n",
    "\n",
    "U = value_iteration(U)\n",
    "for row in U:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
