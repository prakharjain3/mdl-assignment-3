{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World\n",
    "\n",
    "|       | reward + 1 | Penalty -1 |\n",
    "|-------|------------|------------|\n",
    "|       |  &nbsp;    |  &nbsp;    |\n",
    "|       | wall       |            |\n",
    "| start |            |            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1. Write a code in Python implementing Value iteration for a grid world given in the\n",
    "image above\n",
    "Values you will require:\n",
    "1. The reward for reaching the goal state = 1\n",
    "2. The penalty for reaching the red state = -1\n",
    "3. Step cost = -0.04\n",
    "4. Probability of going in the direction of the action = 0.7\n",
    "5. Probability of going in a direction perpendicular to the action = 0.15\n",
    "6. Discount Factor = 0.95\n",
    "Print the utility value of each cell in the grid after each iteration until the values\n",
    "converge. (Assume the values converge when the difference between the utilities\n",
    "for each cell is <= 0.0001)\n",
    "Note: The agent does not change its state if it hits a wall or the boundaries\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the grid world\n",
    "WORLD = np.array([[0, 1, -1],\n",
    "                  [0, 0, 0],\n",
    "                  [0, float('-inf'), 0],\n",
    "                  [float('-inf'), 0, 0]])\n",
    "# print(WORLD)\n",
    "\n",
    "# Define the action set\n",
    "ACTIONS = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "\n",
    "# Define the probabilities for action and perpendicular action\n",
    "PROB_ACTION = 0.7\n",
    "PROB_PERP_ACTION = 0.15\n",
    "\n",
    "# Define the rewards and penalties\n",
    "REWARD_GOAL = 1\n",
    "PENALTY_RED = -1\n",
    "STEP_COST = -0.04\n",
    "\n",
    "# Define the convergence threshold\n",
    "EPSILON = 0.0001\n",
    "\n",
    "# Function to check if a state is valid\n",
    "def is_valid_state(state, world):\n",
    "    row, col = state\n",
    "    rows, cols = world.shape\n",
    "    if row < 0 or row >= rows or col < 0 or col >= cols or world[row, col] == float('-inf'):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Initialize utility values for each cell in the grid\n",
    "utilities = np.zeros_like(WORLD)\n",
    "\n",
    "# Perform Value Iteration\n",
    "delta = float('inf')\n",
    "while delta > EPSILON:\n",
    "    delta = 0\n",
    "    for row in range(WORLD.shape[0]):\n",
    "        for col in range(WORLD.shape[1]):\n",
    "            if not is_valid_state((row, col), WORLD):\n",
    "                continue\n",
    "\n",
    "            prev_utility = utilities[row, col]\n",
    "\n",
    "            max_action_utility = float('-inf')\n",
    "            for action in ACTIONS:\n",
    "                next_row, next_col = row, col\n",
    "                if action == 'UP':\n",
    "                    next_row -= 1\n",
    "                elif action == 'DOWN':\n",
    "                    next_row += 1\n",
    "                elif action == 'LEFT':\n",
    "                    next_col -= 1\n",
    "                elif action == 'RIGHT':\n",
    "                    next_col += 1\n",
    "\n",
    "                next_state = (next_row, next_col)\n",
    "\n",
    "                # Calculate the estimated utility for the current action\n",
    "                estimated_utility = 0\n",
    "                for act in ACTIONS:\n",
    "                    if act == action:\n",
    "                        prob = PROB_ACTION\n",
    "                    else:\n",
    "                        prob = PROB_PERP_ACTION\n",
    "                    next_row, next_col = row, col\n",
    "                    if act == 'UP':\n",
    "                        next_row -= 1\n",
    "                    elif act == 'DOWN':\n",
    "                        next_row += 1\n",
    "                    elif act == 'LEFT':\n",
    "                        next_col -= 1\n",
    "                    elif act == 'RIGHT':\n",
    "                        next_col += 1\n",
    "\n",
    "                    next_state = (next_row, next_col)\n",
    "                    if is_valid_state(next_state, WORLD):\n",
    "                        estimated_utility += prob * utilities[next_row, next_col]\n",
    "                    else:\n",
    "                        estimated_utility += prob * prev_utility\n",
    "\n",
    "                # Update the maximum action utility value\n",
    "                max_action_utility = max(max_action_utility, estimated_utility)\n",
    "\n",
    "            # Update the utility value for the current state\n",
    "            if WORLD[row, col] == REWARD_GOAL:\n",
    "                utilities[row, col] = REWARD_GOAL\n",
    "            elif WORLD[row, col] == PENALTY_RED:\n",
    "                utilities[row, col] = PENALTY_RED\n",
    "            else:\n",
    "                utilities[row, col] = STEP_COST + max_action_utility\n",
    "    print(utilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the grid world\n",
    "WORLD = np.array([[0, 1, -1],\n",
    "                  [0, 0, 0],\n",
    "                  [0, float('-inf'), 0],\n",
    "                  ['x', 0, 0]])\n",
    "\n",
    "# Define the action set\n",
    "ACTIONS = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "\n",
    "# Define the probabilities for action and perpendicular action\n",
    "PROB_ACTION = 0.7\n",
    "PROB_PERP_ACTION = 0.15\n",
    "\n",
    "# Define the rewards and penalties\n",
    "REWARD_GOAL = 1\n",
    "PENALTY_RED = -1\n",
    "STEP_COST = -0.04\n",
    "\n",
    "# Define the convergence threshold\n",
    "EPSILON = 0.0001\n",
    "\n",
    "# Function to check if a state is valid\n",
    "def is_valid_state(state, world):\n",
    "    \"\"\"\n",
    "    Check if a state is valid (within the bounds of the grid).\n",
    "    Args:\n",
    "        state (tuple): Current state (row, col) in the grid.\n",
    "        world (numpy.ndarray): Grid world representation.\n",
    "    Returns:\n",
    "        bool: True if the state is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    row, col = state\n",
    "    rows, cols = world.shape\n",
    "    if row < 0 or row >= rows or col < 0 or col >= cols or world[row, col] == float('-inf'):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Initialize utility values for each cell in the grid\n",
    "utilities = np.zeros_like(WORLD)\n",
    "\n",
    "# Set the start state\n",
    "start_state = (3, 0)\n",
    "\n",
    "# Perform Value Iteration\n",
    "delta = float('inf')\n",
    "while delta > EPSILON:\n",
    "    delta = 0\n",
    "    i = 0\n",
    "    policy = np.empty_like(WORLD, dtype=np.object)\n",
    "    for row in range(WORLD.shape[0]):\n",
    "        for col in range(WORLD.shape[1]):\n",
    "            if not is_valid_state((row, col), WORLD):\n",
    "                policy[row, col] = 'WALL'\n",
    "                continue\n",
    "\n",
    "            prev_utility = utilities[row, col]\n",
    "\n",
    "            max_action_utility = float('-inf')\n",
    "            best_action = None\n",
    "            estimated_utility = 0\n",
    "            for act in ACTIONS:\n",
    "                    if act == action:\n",
    "                        prob = PROB_ACTION\n",
    "                    else:\n",
    "                        prob = PROB_PERP_ACTION\n",
    "                    next_row, next_col = row, col\n",
    "                    if act == 'UP':\n",
    "                        next_row -= 1\n",
    "                    elif act == 'DOWN':\n",
    "                        next_row += 1\n",
    "                    elif act == 'LEFT':\n",
    "                        next_col -= 1\n",
    "                    elif act == 'RIGHT':\n",
    "                        next_col += 1\n",
    "\n",
    "                    next_state = (next_row, next_col)\n",
    "                    if is_valid_state(next_state, WORLD):\n",
    "                        estimated_utility += prob * utilities[next_row, next_col]\n",
    "                    else:\n",
    "                        estimated_utility += prob * prev_utility\n",
    "\n",
    "                # Update the maximum action utility value and the best action\n",
    "            if estimated_utility > max_action_utility:\n",
    "                    max_action_utility = estimated_utility\n",
    "                    best_action = action\n",
    "            policy[row, col] = best_action\n",
    "\n",
    "            # Update the utility value for the current state\n",
    "        if WORLD[row, col] == REWARD_GOAL:\n",
    "                utilities[row, col] = REWARD_GOAL\n",
    "        elif WORLD[row, col] == PENALTY_RED:\n",
    "                utilities[row, col] = PENALTY_RED\n",
    "        else:\n",
    "                utilities[row, col] = STEP_COST + max_action_utility\n",
    "\n",
    "            # Update the delta (maximum change in utility value)\n",
    "        delta = max(delta, abs(prev_utility - utilities[row, col]))\n",
    "\n",
    "    # Print the utility values after each iteration\n",
    "        print(\"Iteration: \", i + 1)\n",
    "        i += 1 \n",
    "    print(utilities)\n",
    "\n",
    "    # Check for convergence\n",
    "    if delta <= EPSILON:\n",
    "        print(\"Convergence achieved after\", i + 1, \"iterations.\")\n",
    "        break\n",
    "'''\n",
    "# Print the final policy\n",
    "policy = np.empty_like(WORLD, dtype=np.object)\n",
    "for row in range(WORLD.shape[0]):\n",
    "    for col in range(WORLD.shape[1]):\n",
    "        if not is_valid_state((row, col), WORLD):\n",
    "            policy[row, col] = 'WALL'\n",
    "        else:\n",
    "            max_action_utility = float('-inf')\n",
    "            best_action = None\n",
    "            for action in ACTIONS:\n",
    "                next_row, next_col = row, col\n",
    "                if action == 'UP':\n",
    "                    next_row -= 1\n",
    "                elif action == 'DOWN':\n",
    "                    next_row += 1\n",
    "                elif action == 'LEFT':\n",
    "                    next_col -= 1\n",
    "                elif action == 'RIGHT':\n",
    "                    next_col += 1\n",
    "\n",
    "                next_state = (next_row, next_col)\n",
    "\n",
    "                # Calculate the estimated utility for the current action\n",
    "                estimated_utility = 0\n",
    "                for act in ACTIONS:\n",
    "                    if act == action:\n",
    "                        prob = PROB_ACTION\n",
    "                    else:\n",
    "                        prob = PROB_PERP_ACTION\n",
    "                    next_row, next_col = row, col\n",
    "                    if act == 'UP':\n",
    "                        next_row -= 1\n",
    "                    elif act == 'DOWN':\n",
    "                        next_row += 1\n",
    "                    elif act == 'LEFT':\n",
    "                        next_col -= 1\n",
    "                    elif act == 'RIGHT':\n",
    "                        next_col += 1\n",
    "\n",
    "                    next_state = (next_row, next_col)\n",
    "                    if is_valid_state(next_state, WORLD):\n",
    "                        estimated_utility += prob * utilities[next_row, next_col]\n",
    "                    else:\n",
    "                        estimated_utility += prob * utilities[row, col]\n",
    "\n",
    "                # Update the maximum action utility value and the best action\n",
    "                if estimated_utility > max_action_utility:\n",
    "                    max_action_utility = estimated_utility\n",
    "                    best_action = action\n",
    "\n",
    "            # Set the best action as the policy for the current state\n",
    "            policy[row, col] = best_action\n",
    "'''\n",
    "# Print the final policy\n",
    "print(\"Final Policy:\")\n",
    "print(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the grid world\n",
    "GRID_ROWS = 4\n",
    "GRID_COLS = 3\n",
    "START_STATE = (3, 0)\n",
    "CURRENT_STATE = START_STATE\n",
    "GOAL_STATE = (0, 2)\n",
    "RED_STATE = (0, 1)\n",
    "WALL_STATE = (2, 1)\n",
    "ACTIONS = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "PROB_ACTION = 0.7\n",
    "PROB_PERP_ACTION = 0.15\n",
    "REWARD_GOAL = 1\n",
    "REWARD_RED = -1\n",
    "REWARD_STEP = -0.04\n",
    "CONVERGENCE_THRESHOLD = 0.0001\n",
    "\n",
    "# Initialize the grid world with initial utility values\n",
    "grid_world = np.zeros((GRID_ROWS, GRID_COLS))\n",
    "\n",
    "def is_valid_state(state, world):\n",
    "    row, col = state\n",
    "    rows, cols = world.shape\n",
    "    if row < 0 or row >= rows or col < 0 or col >= cols or world[row, col] == float('-inf'):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_next_state(state, action):\n",
    "    row, col = state\n",
    "    if action == 'UP':\n",
    "        row -= 1\n",
    "    elif action == 'DOWN':\n",
    "        row += 1\n",
    "    elif action == 'LEFT':\n",
    "        col -= 1\n",
    "    elif action == 'RIGHT':\n",
    "        col += 1\n",
    "    return (row, col)\n",
    "\n",
    "def reward(state):\n",
    "    if state == GOAL_STATE:\n",
    "        return REWARD_GOAL\n",
    "    elif state == RED_STATE:\n",
    "        return REWARD_RED\n",
    "    else:\n",
    "        return REWARD_STEP\n",
    "\n",
    "def get_next_states(state):\n",
    "    next_states = []\n",
    "    for action in ACTIONS:\n",
    "        next_state = get_next_state(state, action)\n",
    "        if is_valid_state(next_state, grid_world):\n",
    "            next_states.append(next_state)\n",
    "    return next_states\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
