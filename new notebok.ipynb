{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility Values after Iteration:\n",
      "[[ 0.          0.         -1.        ]\n",
      " [ 0.          0.         -0.1425    ]\n",
      " [ 0.          0.         -0.02030625]\n",
      " [ 0.          0.         -0.00289364]]\n",
      "\n",
      "Utility Values after Iteration:\n",
      "[[ 0.          0.         -1.02030625]\n",
      " [ 0.         -0.02030625 -0.16179094]\n",
      " [ 0.          0.         -0.02497948]\n",
      " [ 0.         -0.00192427 -0.00483922]]\n",
      "\n",
      "Utility Values after Iteration:\n",
      "[[ 0.          0.         -1.02305521]\n",
      " [-0.00289364 -0.02346755 -0.16495087]\n",
      " [-0.00192427  0.         -0.02672358]\n",
      " [ 0.         -0.00321808 -0.00594813]]\n",
      "\n",
      "Utility Values after Iteration:\n",
      "[[-4.12343789e-04  0.00000000e+00 -1.02350550e+00]\n",
      " [-3.89254345e-03 -2.40601858e-02 -1.65657667e-01]\n",
      " [-2.58854140e-03  0.00000000e+00 -2.75617253e-02]\n",
      " [ 0.00000000e+00 -3.95550781e-03 -6.55795855e-03]]\n",
      "\n",
      "Utility Values after Iteration:\n",
      "[[-5.54687442e-04  0.00000000e+00 -1.02360622e+00]\n",
      " [-4.16631077e-03 -2.41999168e-02 -1.65884377e-01]\n",
      " [-2.77059666e-03  0.00000000e+00 -2.79995661e-02]\n",
      " [ 0.00000000e+00 -4.36104244e-03 -6.89003139e-03]]\n",
      "\n",
      "Utility Values after Iteration:\n",
      "[[-5.93699285e-04  0.00000000e+00 -1.02363852e+00]\n",
      " [-4.23810819e-03 -2.42424541e-02 -1.65979660e-01]\n",
      " [-2.81834195e-03  0.00000000e+00 -2.82339724e-02]\n",
      " [ 0.00000000e+00 -4.58187087e-03 -7.07028520e-03]]\n",
      "\n",
      "Utility Values after Iteration:\n",
      "[[-6.03930417e-04  0.00000000e+00 -1.02365210e+00]\n",
      " [-4.25777716e-03 -2.42588348e-02 -1.66025891e-01]\n",
      " [-2.83142181e-03  0.00000000e+00 -2.83604291e-02]\n",
      " [ 0.00000000e+00 -4.70173966e-03 -7.16801801e-03]]\n",
      "\n",
      "Utility Values after Iteration:\n",
      "[[-6.06733245e-04  0.00000000e+00 -1.02365869e+00]\n",
      " [-4.26383917e-03 -2.42662865e-02 -1.66049805e-01]\n",
      " [-2.83545305e-03  0.00000000e+00 -2.84288292e-02]\n",
      " [ 0.00000000e+00 -4.76673198e-03 -7.22098492e-03]]\n",
      "\n",
      "Best Policy after Convergence:\n",
      "R\tG\tL\t\n",
      "U\tU\tL\t\n",
      "U\tW\tD\t\n",
      "W\tR\tL\t\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the grid world as a 2D numpy array\n",
    "grid_world = np.array([[0, 1, -1],\n",
    "                       [0, 0, 0],\n",
    "                       [0, float('inf'), 0],\n",
    "                       [float('inf'), 0, 0]])\n",
    "\n",
    "# Define the actions (up, down, left, right)\n",
    "actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "\n",
    "# Define the transition probabilities\n",
    "prob_action = 0.7\n",
    "prob_perpendicular = 0.15\n",
    "\n",
    "# Define the rewards and penalties\n",
    "reward_goal = 1\n",
    "penalty_red = -1\n",
    "step_cost = -0.04\n",
    "\n",
    "# Define the discount factor\n",
    "discount_factor = 0.95\n",
    "\n",
    "# Initialize the utility values\n",
    "num_rows, num_cols = grid_world.shape\n",
    "utilities = np.zeros((num_rows, num_cols))\n",
    "\n",
    "# Helper function to check if a cell is valid (i.e., not a wall or out of bounds)\n",
    "def is_valid_cell(row, col):\n",
    "    return row >= 0 and row < num_rows and col >= 0 and col < num_cols and grid_world[row][col] != float('inf')\n",
    "\n",
    "# Value Iteration algorithm\n",
    "while True:\n",
    "    # Initialize the delta for convergence check\n",
    "    delta = 0\n",
    "    \n",
    "    # Update the utility values for each cell\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            # Skip walls and goal state\n",
    "            if grid_world[row][col] == float('inf') or grid_world[row][col] == reward_goal:\n",
    "                continue\n",
    "            \n",
    "            # Get the current utility value\n",
    "            current_utility = utilities[row][col]\n",
    "            \n",
    "            # Initialize the maximum utility value for the current cell\n",
    "            max_utility = float('-inf')\n",
    "            \n",
    "            # Try each action and compute the expected utility value\n",
    "            for action in actions:\n",
    "                # Compute the next state after taking the action\n",
    "                next_row = row + action[0]\n",
    "                next_col = col + action[1]\n",
    "                \n",
    "                # Check if the next state is valid\n",
    "                if is_valid_cell(next_row, next_col):\n",
    "                    # Compute the expected utility value for the current action\n",
    "                    expected_utility = prob_action * utilities[next_row][next_col]\n",
    "                    \n",
    "                    # Compute the expected utility values for the two perpendicular actions\n",
    "                    for perpendicular_action in actions:\n",
    "                        if perpendicular_action != action:\n",
    "                            perpendicular_row = row + perpendicular_action[0]\n",
    "                            perpendicular_col = col + perpendicular_action[1]\n",
    "                            if is_valid_cell(perpendicular_row, perpendicular_col):\n",
    "                                expected_utility += prob_perpendicular * utilities[perpendicular_row][perpendicular_col]\n",
    "                    \n",
    "                    # Update the maximum utility value\n",
    "                    max_utility = max(max_utility, expected_utility)\n",
    "            \n",
    "            # Update the utility value for the current cell\n",
    "            utilities[row][col] = grid_world[row][col] + discount_factor * max_utility\n",
    "            \n",
    "            # Update the delta for convergence check\n",
    "            delta = max(delta, abs(current_utility - utilities[row][col]))\n",
    "    \n",
    "    # Print the current utility values\n",
    "    print(\"Utility Values after Iteration:\")\n",
    "    print(utilities)\n",
    "    print()\n",
    "    \n",
    "    # Check for convergence\n",
    "    if delta <= 0.0001:\n",
    "        break\n",
    "\n",
    "# Compute the best policy for each cell\n",
    "# Compute the best policy for each cell\n",
    "best_policy = np.zeros((num_rows, num_cols), dtype=str)\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        # Skip walls\n",
    "        if grid_world[row][col] == float('inf'):\n",
    "            best_policy[row][col] = 'WALL'\n",
    "            continue\n",
    "\n",
    "        # Skip goal state\n",
    "        if grid_world[row][col] == reward_goal:\n",
    "            best_policy[row][col] = 'GOAL'\n",
    "            continue\n",
    "\n",
    "        # Initialize the maximum expected utility and best action\n",
    "        max_expected_utility = float('-inf')\n",
    "        best_action = None\n",
    "\n",
    "        # Try each action and compute the expected utility value\n",
    "        for action_idx, action in enumerate(actions):\n",
    "            # Compute the next state after taking the action\n",
    "            next_row = row + action[0]\n",
    "            next_col = col + action[1]\n",
    "\n",
    "            # Check if the next state is valid\n",
    "            if is_valid_cell(next_row, next_col):\n",
    "                # Compute the expected utility value for the current action\n",
    "                expected_utility = prob_action * utilities[next_row][next_col]\n",
    "\n",
    "                # Compute the expected utility values for the two perpendicular actions\n",
    "                for perpendicular_action in actions:\n",
    "                    if perpendicular_action != action:\n",
    "                        perpendicular_row = row + perpendicular_action[0]\n",
    "                        perpendicular_col = col + perpendicular_action[1]\n",
    "                        if is_valid_cell(perpendicular_row, perpendicular_col):\n",
    "                            expected_utility += prob_perpendicular * utilities[perpendicular_row][perpendicular_col]\n",
    "\n",
    "                # Update the maximum expected utility and best action\n",
    "                if expected_utility > max_expected_utility:\n",
    "                    max_expected_utility = expected_utility\n",
    "                    best_action = action_idx\n",
    "\n",
    "        # Map the best action to a direction for the current cell\n",
    "        if best_action is not None:\n",
    "            if best_action == 0:\n",
    "                best_policy[row][col] = 'UP'\n",
    "            elif best_action == 1:\n",
    "                best_policy[row][col] = 'DOWN'\n",
    "            elif best_action == 2:\n",
    "                best_policy[row][col] = 'LEFT'\n",
    "            elif best_action == 3:\n",
    "                best_policy[row][col] = 'RIGHT'\n",
    "\n",
    "# Print the best policy\n",
    "print(\"Best Policy after Convergence:\")\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        print(best_policy[row][col], end='\\t')\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
